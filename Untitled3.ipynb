{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b81057",
   "metadata": {},
   "source": [
    "## 搭建单层神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e4f6792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "# 利用鸢尾花数据集，实现前向传播、反向传播，可视化loss曲线\n",
    "\n",
    "# 导入所需模块\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e4821d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据，分别为输入特征和标签\n",
    "x_data = datasets.load_iris().data\n",
    "y_data = datasets.load_iris().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a7d5658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）\n",
    "# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）\n",
    "np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n",
    "np.random.shuffle(x_data)\n",
    "# seed值是用完即弃\n",
    "np.random.seed(116)\n",
    "np.random.shuffle(y_data)\n",
    "# 这里代码习惯无实际意义\n",
    "tf.random.set_seed(116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1445db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行\n",
    "x_train = x_data[:-30]\n",
    "y_train = y_data[:-30]\n",
    "x_test = x_data[-30:]\n",
    "y_test = y_data[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e584af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "x_test = tf.cast(x_test, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6601a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8c169cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
    "# 用tf.Variable()标记参数可训练\n",
    "# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）\n",
    "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
    "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "55df6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1  # 学习率为0.1\n",
    "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
    "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
    "epoch = 500  # 循环500轮\n",
    "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和\n",
    "\n",
    "\n",
    "########################动量梯度下降SGDM##################################\n",
    "# m_w, m_b = 0, 0\n",
    "# beta = 0.9\n",
    "##########################################################################\n",
    "\n",
    "#########################adagrad##########################################\n",
    "# v_w, v_b = 0, 0\n",
    "##########################################################################\n",
    "\n",
    "##########################RMSprop#########################################\n",
    "# v_w, v_b = 0, 0\n",
    "# beta = 0.9\n",
    "##########################################################################\n",
    "\n",
    "############################Adam##########################################\n",
    "m_w, m_b = 0, 0\n",
    "v_w, v_b = 0, 0\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "delta_w, delta_b = 0, 0\n",
    "global_step = 0\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "859dbb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.21984169632196426\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 1, loss: 0.14480622299015522\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 2, loss: 0.10274341702461243\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 3, loss: 0.08922167122364044\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 4, loss: 0.08600791078060865\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 5, loss: 0.06994976848363876\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 6, loss: 0.06724478211253881\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 7, loss: 0.061045452021062374\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 8, loss: 0.055738055147230625\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 9, loss: 0.0540529265999794\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 10, loss: 0.04909192491322756\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 11, loss: 0.048258716240525246\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 12, loss: 0.04458607081323862\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 13, loss: 0.043710325844585896\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 14, loss: 0.04151798412203789\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 15, loss: 0.04042436275631189\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 16, loss: 0.03921916848048568\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 17, loss: 0.037702302914112806\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 18, loss: 0.03746742429211736\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 19, loss: 0.035456123761832714\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 20, loss: 0.03618234721943736\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 21, loss: 0.033532277680933475\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 22, loss: 0.03510434087365866\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 23, loss: 0.03179901698604226\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 24, loss: 0.03405483579263091\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 25, loss: 0.03026510216295719\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 26, loss: 0.0328838094137609\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 27, loss: 0.0289817675948143\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 28, loss: 0.031539647839963436\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 29, loss: 0.02803809428587556\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 30, loss: 0.030121177900582552\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 31, loss: 0.027460424229502678\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 32, loss: 0.028777121100574732\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 33, loss: 0.027132852468639612\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 34, loss: 0.027615332044661045\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 35, loss: 0.02686211373656988\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 36, loss: 0.026687213219702244\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 37, loss: 0.026502931490540504\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 38, loss: 0.02599624264985323\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 39, loss: 0.026023707818239927\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 40, loss: 0.025497335474938154\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 41, loss: 0.025481839198619127\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 42, loss: 0.025107067078351974\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 43, loss: 0.0249576224014163\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 44, loss: 0.024743789806962013\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 45, loss: 0.02450238447636366\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 46, loss: 0.024368162266910076\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 47, loss: 0.024121191818267107\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 48, loss: 0.02398698963224888\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 49, loss: 0.023787254700437188\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 50, loss: 0.02362554846331477\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 51, loss: 0.023471766849979758\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 52, loss: 0.02329925331287086\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 53, loss: 0.02316384599544108\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 54, loss: 0.023004947928711772\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 55, loss: 0.02286858344450593\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 56, loss: 0.02273069485090673\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 57, loss: 0.02259322186000645\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 58, loss: 0.022468625335022807\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 59, loss: 0.022338303737342358\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 60, loss: 0.022218438098207116\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 61, loss: 0.02209912915714085\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 62, loss: 0.021982431644573808\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 63, loss: 0.021871635457500815\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 64, loss: 0.02176067396067083\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 65, loss: 0.021654900163412094\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 66, loss: 0.02155095594935119\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 67, loss: 0.021449323976412416\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 68, loss: 0.02135123359039426\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 69, loss: 0.02125449851155281\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 70, loss: 0.02116078929975629\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 71, loss: 0.0210691352840513\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 72, loss: 0.02097941329702735\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 73, loss: 0.02089215791784227\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 74, loss: 0.02080653514713049\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 75, loss: 0.020723016001284122\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 76, loss: 0.020641346462070942\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 77, loss: 0.020561337238177657\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 78, loss: 0.020483182976022363\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 79, loss: 0.02040658611804247\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 80, loss: 0.02033161697909236\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 81, loss: 0.020258216885849833\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 82, loss: 0.020186257548630238\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 83, loss: 0.020115777384489775\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 84, loss: 0.020046671386808157\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 85, loss: 0.019978909054771066\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 86, loss: 0.019912461983039975\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 87, loss: 0.019847262650728226\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 88, loss: 0.019783300580456853\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 89, loss: 0.019720504991710186\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 90, loss: 0.019658871460705996\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 91, loss: 0.019598338287323713\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 92, loss: 0.01953887823037803\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 93, loss: 0.01948049501515925\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 94, loss: 0.01942308945581317\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 95, loss: 0.01936669507995248\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 96, loss: 0.019311260897666216\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 97, loss: 0.019256733590736985\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 98, loss: 0.01920313131995499\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 99, loss: 0.019150403328239918\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 100, loss: 0.019098521675914526\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 101, loss: 0.019047496374696493\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 102, loss: 0.01899724919348955\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 103, loss: 0.018947818549349904\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 104, loss: 0.018899137619882822\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 105, loss: 0.01885121106170118\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 106, loss: 0.01880401815287769\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 107, loss: 0.01875753398053348\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 108, loss: 0.018711727112531662\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 109, loss: 0.018666625022888184\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 110, loss: 0.018622153904289007\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111, loss: 0.018578326795250177\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 112, loss: 0.018535152077674866\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 113, loss: 0.018492563627660275\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 114, loss: 0.018450571689754725\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 115, loss: 0.01840919884853065\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 116, loss: 0.018368357326835394\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 117, loss: 0.018328095320612192\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 118, loss: 0.018288367427885532\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 119, loss: 0.018249173648655415\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 120, loss: 0.018210515147075057\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 121, loss: 0.018172351410612464\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 122, loss: 0.018134692683815956\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 123, loss: 0.01809751079417765\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 124, loss: 0.01806082110852003\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 125, loss: 0.018024591030552983\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 126, loss: 0.017988815205171704\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 127, loss: 0.017953495727851987\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 128, loss: 0.01791860954836011\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 129, loss: 0.017884156899526715\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 130, loss: 0.017850117990747094\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 131, loss: 0.017816500272601843\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 132, loss: 0.01778327813372016\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 133, loss: 0.017750471364706755\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 134, loss: 0.017718041548505425\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 135, loss: 0.01768598728813231\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 136, loss: 0.017654338851571083\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 137, loss: 0.01762299961410463\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 138, loss: 0.017592079238966107\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 139, loss: 0.01756148785352707\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 140, loss: 0.017531224759295583\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 141, loss: 0.01750134490430355\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 142, loss: 0.017471767030656338\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 143, loss: 0.017442526761442423\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 144, loss: 0.01741361292079091\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 145, loss: 0.017385010607540607\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 146, loss: 0.01735672657378018\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 147, loss: 0.017328754533082247\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 148, loss: 0.017301076790317893\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 149, loss: 0.017273682402446866\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 150, loss: 0.017246593721210957\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 151, loss: 0.017219791188836098\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 152, loss: 0.017193261766806245\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 153, loss: 0.017167019424960017\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 154, loss: 0.017141046468168497\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 155, loss: 0.017115336377173662\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 156, loss: 0.017089897068217397\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 157, loss: 0.017064700834453106\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 158, loss: 0.017039781901985407\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 159, loss: 0.017015099292621017\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 160, loss: 0.016990660689771175\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 161, loss: 0.016966478433459997\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 162, loss: 0.016942529706284404\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 163, loss: 0.016918811248615384\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 164, loss: 0.016895329114049673\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 165, loss: 0.016872074687853456\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 166, loss: 0.016849044477567077\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 167, loss: 0.016826242208480835\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 168, loss: 0.01680366275832057\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 169, loss: 0.016781276324763894\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 170, loss: 0.016759124118834734\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 171, loss: 0.016737164463847876\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 172, loss: 0.016715420642867684\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 173, loss: 0.01669387030415237\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 174, loss: 0.01667253510095179\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 175, loss: 0.016651396406814456\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 176, loss: 0.016630438156425953\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 177, loss: 0.016609677579253912\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 178, loss: 0.016589109785854816\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 179, loss: 0.016568724066019058\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 180, loss: 0.016548524843528867\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 181, loss: 0.01652849931269884\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 182, loss: 0.01650867168791592\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 183, loss: 0.016488999594002962\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 184, loss: 0.016469509107992053\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 185, loss: 0.016450190916657448\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 186, loss: 0.01643104711547494\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 187, loss: 0.016412064898759127\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 188, loss: 0.016393240075558424\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 189, loss: 0.016374600119888783\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 190, loss: 0.016356087755411863\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 191, loss: 0.0163377714343369\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 192, loss: 0.016319578047841787\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 193, loss: 0.016301557887345552\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 194, loss: 0.0162836997769773\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 195, loss: 0.016265966231003404\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 196, loss: 0.01624839659780264\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 197, loss: 0.016230974346399307\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 198, loss: 0.01621368620544672\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 199, loss: 0.016196555458009243\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 200, loss: 0.016179553931578994\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 201, loss: 0.016162707470357418\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 202, loss: 0.016145979054272175\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 203, loss: 0.01612940733321011\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 204, loss: 0.01611295319162309\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 205, loss: 0.016096643637865782\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 206, loss: 0.016080466099083424\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 207, loss: 0.016064401948824525\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 208, loss: 0.016048480989411473\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 209, loss: 0.016032689018175006\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 210, loss: 0.016017000190913677\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 211, loss: 0.016001461073756218\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 212, loss: 0.015986038837581873\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 213, loss: 0.01597071369178593\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 214, loss: 0.015955534763634205\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 215, loss: 0.015940468991175294\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 216, loss: 0.0159255163744092\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 217, loss: 0.01591068017296493\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 218, loss: 0.01589596178382635\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 219, loss: 0.015881340019404888\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 220, loss: 0.015866846311837435\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221, loss: 0.01585244690068066\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 222, loss: 0.01583817321807146\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 223, loss: 0.015824010130017996\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 224, loss: 0.015809929464012384\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 225, loss: 0.015795977087691426\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 226, loss: 0.015782118774950504\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 227, loss: 0.01576835918240249\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 228, loss: 0.015754715772345662\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 229, loss: 0.015741158509626985\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 230, loss: 0.015727706952020526\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 231, loss: 0.015714354580268264\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 232, loss: 0.01570110279135406\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 233, loss: 0.015687945298850536\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 234, loss: 0.015674875816330314\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 235, loss: 0.015661909710615873\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 236, loss: 0.015649032313376665\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 237, loss: 0.015636249678209424\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 238, loss: 0.015623550862073898\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 239, loss: 0.015610967995598912\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 240, loss: 0.01559843891300261\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 241, loss: 0.015586013440042734\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 242, loss: 0.015573690412566066\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 243, loss: 0.015561424661427736\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 244, loss: 0.015549275209195912\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 245, loss: 0.015537195489741862\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 246, loss: 0.015525190392509103\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 247, loss: 0.015513290534727275\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 248, loss: 0.015501457382924855\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 249, loss: 0.015489710262045264\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 250, loss: 0.015478044166229665\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 251, loss: 0.015466456417925656\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 252, loss: 0.015454944572411478\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 253, loss: 0.015443522366695106\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 254, loss: 0.015432165702804923\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 255, loss: 0.015420888317748904\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 256, loss: 0.015409696148708463\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 257, loss: 0.015398563700728118\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 258, loss: 0.01538752275519073\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 259, loss: 0.015376552008092403\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 260, loss: 0.015365640632808208\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 261, loss: 0.0153548086527735\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 262, loss: 0.015344052808359265\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 263, loss: 0.015333368792198598\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 264, loss: 0.015322737046517432\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 265, loss: 0.015312214731238782\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 266, loss: 0.015301717212423682\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 267, loss: 0.015291301300749183\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 268, loss: 0.015280968858860433\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 269, loss: 0.015270687057636678\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 270, loss: 0.015260471380315721\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 271, loss: 0.015250333352014422\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 272, loss: 0.015240255859680474\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 273, loss: 0.015230226912535727\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 274, loss: 0.015220288070850074\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 275, loss: 0.015210391371510923\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 276, loss: 0.015200558234937489\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 277, loss: 0.015190806239843369\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 278, loss: 0.015181111986748874\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 279, loss: 0.015171448118053377\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 280, loss: 0.015161873074248433\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 281, loss: 0.015152372070588171\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 282, loss: 0.015142892254516482\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 283, loss: 0.015133494860492647\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 284, loss: 0.01512414833996445\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 285, loss: 0.01511485013179481\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 286, loss: 0.015105641563422978\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 287, loss: 0.015096449758857489\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 288, loss: 0.015087349689565599\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 289, loss: 0.015078280004672706\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 290, loss: 0.015069273998960853\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 291, loss: 0.01506031770259142\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 292, loss: 0.015051414724439383\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 293, loss: 0.015042576123960316\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 294, loss: 0.01503378467168659\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 295, loss: 0.015025043860077858\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 296, loss: 0.015016354736872017\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 297, loss: 0.015007726266048849\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 298, loss: 0.014999139355495572\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 299, loss: 0.0149906100705266\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 300, loss: 0.014982125838287175\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 301, loss: 0.01497369643766433\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 302, loss: 0.014965311740525067\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 303, loss: 0.014956981060095131\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 304, loss: 0.014948690892197192\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 305, loss: 0.014940456137992442\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 306, loss: 0.014932267251424491\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 307, loss: 0.01492413249798119\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 308, loss: 0.01491604174952954\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 309, loss: 0.01490797579754144\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 310, loss: 0.014899985049851239\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 311, loss: 0.014892029925249517\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 312, loss: 0.014884122530929744\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 313, loss: 0.014876257395371795\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 314, loss: 0.014868429279886186\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 315, loss: 0.014860664843581617\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 316, loss: 0.014852930908091366\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 317, loss: 0.014845235855318606\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 318, loss: 0.014837597729638219\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 319, loss: 0.014829996740445495\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 320, loss: 0.014822431490756571\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 321, loss: 0.01481492433231324\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 322, loss: 0.014807444531470537\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 323, loss: 0.014800010598264635\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 324, loss: 0.01479261729400605\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 325, loss: 0.014785277307964861\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 326, loss: 0.01477795431856066\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 327, loss: 0.014770680572837591\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 328, loss: 0.01476346340496093\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 329, loss: 0.014756266376934946\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 330, loss: 0.014749110443517566\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 331, loss: 0.01474200445227325\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332, loss: 0.014734929543919861\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 333, loss: 0.014727888512425125\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 334, loss: 0.014720902661792934\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 335, loss: 0.014713937183842063\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 336, loss: 0.014707002905197442\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 337, loss: 0.01470013742800802\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 338, loss: 0.014693267061375082\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 339, loss: 0.014686474809423089\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 340, loss: 0.014679688611067832\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 341, loss: 0.014672940596938133\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 342, loss: 0.014666255912743509\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 343, loss: 0.014659578097052872\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 344, loss: 0.014652942889370024\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 345, loss: 0.014646335854195058\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 346, loss: 0.014639779808931053\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 347, loss: 0.014633244252763689\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 348, loss: 0.014626749907620251\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 349, loss: 0.014620291534811258\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 350, loss: 0.014613853418268263\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 351, loss: 0.014607468037866056\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 352, loss: 0.014601105591282248\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 353, loss: 0.014594770153053105\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 354, loss: 0.014588484656997025\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 355, loss: 0.014582206960767508\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 356, loss: 0.014575983514077961\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 357, loss: 0.01456978206988424\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 358, loss: 0.014563610660843551\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 359, loss: 0.014557470218278468\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 360, loss: 0.014551364700309932\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 361, loss: 0.014545284095220268\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 362, loss: 0.01453923445660621\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 363, loss: 0.014533234410919249\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 364, loss: 0.014527249964885414\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 365, loss: 0.014521277393214405\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 366, loss: 0.014515372342430055\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 367, loss: 0.014509465778246522\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 368, loss: 0.014503599493764341\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 369, loss: 0.014497761731036007\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 370, loss: 0.014491963316686451\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 371, loss: 0.014486180734820664\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 372, loss: 0.014480425044894218\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 373, loss: 0.014474702184088528\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 374, loss: 0.014469011803157628\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 375, loss: 0.014463342493399978\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 376, loss: 0.014457699144259095\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 377, loss: 0.014452089089900255\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 378, loss: 0.014446513610891998\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 379, loss: 0.014440945931710303\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 380, loss: 0.014435411314480007\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 381, loss: 0.014429928036406636\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 382, loss: 0.014424438355490565\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 383, loss: 0.014418987440876663\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 384, loss: 0.014413569238968194\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 385, loss: 0.014408172224648297\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 386, loss: 0.014402784989215434\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 387, loss: 0.014397448976524174\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 388, loss: 0.01439213112462312\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 389, loss: 0.014386822585947812\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 390, loss: 0.014381555491127074\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 391, loss: 0.014376313891261816\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 392, loss: 0.014371081837452948\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 393, loss: 0.014365884475409985\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 394, loss: 0.014360718196257949\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 395, loss: 0.01435556320939213\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 396, loss: 0.014350438956171274\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 397, loss: 0.014345343341119587\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 398, loss: 0.014340267633087933\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 399, loss: 0.014335202402435243\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 400, loss: 0.014330183039419353\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 401, loss: 0.014325173338875175\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 402, loss: 0.014320184825919569\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 403, loss: 0.014315235428512096\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 404, loss: 0.014310286496765912\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 405, loss: 0.014305363059975207\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 406, loss: 0.014300483162514865\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 407, loss: 0.014295609900727868\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 408, loss: 0.014290762366726995\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 409, loss: 0.014285926125012338\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 410, loss: 0.014281131443567574\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 411, loss: 0.014276352943852544\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 412, loss: 0.014271578402258456\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 413, loss: 0.014266838203184307\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 414, loss: 0.014262119657360017\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 415, loss: 0.014257422997616231\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 416, loss: 0.014252753928303719\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 417, loss: 0.014248087303712964\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 418, loss: 0.014243456651456654\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 419, loss: 0.014238844974897802\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 420, loss: 0.014234247268177569\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 421, loss: 0.01422967272810638\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 422, loss: 0.014225123217329383\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 423, loss: 0.01422058732714504\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 424, loss: 0.014216068317182362\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 425, loss: 0.014211583300493658\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 426, loss: 0.014207108528353274\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 427, loss: 0.014202647027559578\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 428, loss: 0.014198219287209213\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 429, loss: 0.01419380574952811\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 430, loss: 0.0141893943073228\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 431, loss: 0.014185023377649486\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 432, loss: 0.014180671772919595\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 433, loss: 0.014176320401020348\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 434, loss: 0.014172001858241856\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 435, loss: 0.014167710556648672\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 436, loss: 0.014163408079184592\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 437, loss: 0.01415915449615568\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 438, loss: 0.014154910459183156\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 439, loss: 0.014150667586363852\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 440, loss: 0.0141464649932459\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 441, loss: 0.01414227846544236\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 442, loss: 0.014138084021396935\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 443, loss: 0.014133932651020586\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444, loss: 0.01412980630993843\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 445, loss: 0.014125670655630529\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 446, loss: 0.014121562126092613\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 447, loss: 0.014117482234723866\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 448, loss: 0.014113402692601085\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 449, loss: 0.014109346200712025\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 450, loss: 0.014105319161899388\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 451, loss: 0.014101282926276326\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 452, loss: 0.014097290113568306\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 453, loss: 0.01409330335445702\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 454, loss: 0.014089325326494873\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 455, loss: 0.014085388043895364\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 456, loss: 0.014081434230320156\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 457, loss: 0.014077516389079392\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 458, loss: 0.014073614845983684\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 459, loss: 0.014069720287807286\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 460, loss: 0.014065849245525897\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 461, loss: 0.014061991358175874\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 462, loss: 0.014058153727091849\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 463, loss: 0.014054320519790053\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 464, loss: 0.014050515368580818\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 465, loss: 0.014046711497940123\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 466, loss: 0.014042935683391988\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 467, loss: 0.01403917302377522\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 468, loss: 0.014035413623787463\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 469, loss: 0.01403168321121484\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 470, loss: 0.014027965487912297\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 471, loss: 0.014024261618033051\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 472, loss: 0.014020562870427966\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 473, loss: 0.014016888802871108\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 474, loss: 0.01401324023026973\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 475, loss: 0.01400957873556763\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 476, loss: 0.014005965203978121\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 477, loss: 0.014002340263687074\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 478, loss: 0.013998733600601554\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 479, loss: 0.01399514137301594\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 480, loss: 0.013991574407555163\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 481, loss: 0.013988001039251685\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 482, loss: 0.013984463643282652\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 483, loss: 0.013980927527882159\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 484, loss: 0.013977408641949296\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 485, loss: 0.013973906286992133\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 486, loss: 0.013970415340736508\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 487, loss: 0.01396693172864616\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 488, loss: 0.01396346918772906\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 489, loss: 0.013960021897219121\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 490, loss: 0.013956577749922872\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 491, loss: 0.013953155954368412\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 492, loss: 0.013949745916761458\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 493, loss: 0.013946338789537549\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 494, loss: 0.013942957972176373\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 495, loss: 0.013939591241069138\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 496, loss: 0.013936234056018293\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 497, loss: 0.013932882226072252\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 498, loss: 0.013929551234468818\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 499, loss: 0.013926219311542809\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "total_time 10.575971841812134\n"
     ]
    }
   ],
   "source": [
    "# 训练部分\n",
    "now_time = time.time() \n",
    "for epoch in range(epoch):  #数据集级别的循环，每个epoch循环一次数据集\n",
    "    for step, (x_train, y_train) in enumerate(train_db):  #batch级别的循环 ，每个step循环一个batch 120个训练样本共4个batch\n",
    "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
    "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
    "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
    "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
    "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
    "            # 不用numpy 也ok\n",
    "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
    "        # 计算loss对各个参数的梯度\n",
    "        grads = tape.gradient(loss, [w1, b1])\n",
    "\n",
    "        # 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad \n",
    "        ## SGD随机梯度下降\n",
    "        #########################################\n",
    "#         w1.assign_sub(lr * grads[0])  # 参数w1自更新\n",
    "#         b1.assign_sub(lr * grads[1])  # 参数b自更新\n",
    "        #########################################\n",
    "        \n",
    "        ## sgd-momentun  \n",
    "        #########################################\n",
    "#         m_w = beta * m_w + (1 - beta) * grads[0]\n",
    "#         m_b = beta * m_b + (1 - beta) * grads[1]\n",
    "#         w1.assign_sub(lr * m_w)\n",
    "#         b1.assign_sub(lr * m_b)\n",
    "        #########################################\n",
    "    \n",
    "        ## adagrad\n",
    "        #########################################\n",
    "#         v_w += tf.square(grads[0])\n",
    "#         v_b += tf.square(grads[1])\n",
    "#         w1.assign_sub(lr * grads[0] / tf.sqrt(v_w))\n",
    "#         b1.assign_sub(lr * grads[1] / tf.sqrt(v_b))\n",
    "        #########################################\n",
    "        \n",
    "        ## rmsprop\n",
    "        #########################################\n",
    "#         v_w = beta * v_w + (1 - beta) * tf.square(grads[0])\n",
    "#         v_b = beta * v_b + (1 - beta) * tf.square(grads[1])\n",
    "#         w1.assign_sub(lr * grads[0] / tf.sqrt(v_w))\n",
    "#         b1.assign_sub(lr * grads[1] / tf.sqrt(v_b))\n",
    "        #########################################\n",
    "        \n",
    "        ## adam\n",
    "        #########################################\n",
    "        global_step += 1\n",
    "        m_w = beta1 * m_w + (1 - beta1) * grads[0]\n",
    "        m_b = beta1 * m_b + (1 - beta1) * grads[1]\n",
    "        v_w = beta2 * v_w + (1 - beta2) * tf.square(grads[0])\n",
    "        v_b = beta2 * v_b + (1 - beta2) * tf.square(grads[1])\n",
    "\n",
    "        m_w_correction = m_w / (1 - tf.pow(beta1, int(global_step)))\n",
    "        m_b_correction = m_b / (1 - tf.pow(beta1, int(global_step)))\n",
    "        v_w_correction = v_w / (1 - tf.pow(beta2, int(global_step)))\n",
    "        v_b_correction = v_b / (1 - tf.pow(beta2, int(global_step)))\n",
    "\n",
    "        w1.assign_sub(lr * m_w_correction / tf.sqrt(v_w_correction))\n",
    "        b1.assign_sub(lr * m_b_correction / tf.sqrt(v_b_correction))\n",
    "        #########################################\n",
    "\n",
    "    # 每个epoch，打印loss信息 4个batch\n",
    "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all/4))\n",
    "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
    "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
    "\n",
    "    # 测试部分\n",
    "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
    "    total_correct, total_number = 0, 0\n",
    "    for x_test, y_test in test_db:\n",
    "        # 使用更新后的参数进行预测\n",
    "        y = tf.matmul(x_test, w1) + b1\n",
    "        y = tf.nn.softmax(y)\n",
    "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类，y不为int 所以不能用one_hot\n",
    "        # 将pred转换为y_test的数据类型\n",
    "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
    "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
    "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
    "        # 将每个batch的correct数加起来\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        # 将所有batch中的correct数加起来\n",
    "        total_correct += int(correct)\n",
    "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
    "        total_number += x_test.shape[0]\n",
    "    # 总的准确率等于total_correct/total_number\n",
    "    acc = total_correct / total_number\n",
    "    test_acc.append(acc)\n",
    "    print(\"Test_acc:\", acc)\n",
    "    print(\"--------------------------\")\n",
    "total_time = time.time() - now_time  \n",
    "print(\"total_time\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "04030c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制 loss 曲线\n",
    "plt.title('Loss Function Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Loss')  # y轴变量名称\n",
    "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
    "plt.legend()  # 画出曲线图标\n",
    "plt.show()  # 画出图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8e836018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制 Accuracy 曲线\n",
    "plt.title('Acc Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Acc')  # y轴变量名称\n",
    "plt.plot(test_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd5a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow28",
   "language": "python",
   "name": "tensorflow28"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
